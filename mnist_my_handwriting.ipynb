{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_my_handwriting.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1FoXtcGqtNhjJXZYkj5FRrq_u4PRTtc8B",
      "authorship_tag": "ABX9TyOgYVKyzO8uUHBkh4/G5PsJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bangse94/hongik_ee/blob/master/mnist_my_handwriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48QL9GfUyVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ===========================\n",
        "# import library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "print(\"TensorFlow version : \", tf.__version__)\n",
        "#===========================\n",
        "# import mnist dataset\n",
        "#===========================\n",
        "(train_image, train_labels), (test_image, test_labels) = mnist.load_data()\n",
        "#===========================\n",
        "# reshape input data\n",
        "#===========================\n",
        "train_image = train_image.reshape(train_image.shape[0], 28, 28, 1)\n",
        "test_image = test_image.reshape(test_image.shape[0], 28, 28, 1)\n",
        "train_image = train_image.astype('float32')/255\n",
        "test_image = test_image.astype('float32')/255\n",
        "#===========================\n",
        "# train labels\n",
        "#===========================\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "#===========================\n",
        "# model creation by sequential class\n",
        "#===========================\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "#===========================\n",
        "# data augmentation\n",
        "#===========================\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=50,\n",
        "        width_shift_range=0.3,\n",
        "        height_shift_range=0.3,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "#===========================\n",
        "# model compile and training\n",
        "#===========================\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(train_image, train_labels, batch_size=128),\n",
        "                    steps_per_epoch=train_image.shape[0] // 128,\n",
        "                    validation_data=(test_image, test_labels),\n",
        "                    epochs=20)\n",
        "#===========================\n",
        "# model evaluate\n",
        "#===========================\n",
        "acc = model.evaluate(test_image, test_labels)\n",
        "print('evaluate accuracy:', acc[1])\n",
        "\n",
        "#===========================\n",
        "# save model\n",
        "#===========================\n",
        "model.save('mnist_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ixDc7MntpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#load model\n",
        "model = load_model('mnist_model.h5')\n",
        "\n",
        "class Trace():\n",
        "    def GetImage(self, **kwargs):\n",
        "        self.src_image = kwargs['image']\n",
        "        self.img_color = cv2.imread(\"/content/\"+ str(self.src_image), cv2.IMREAD_COLOR)\n",
        "\n",
        "        return self.img_color\n",
        "\n",
        "    def ImageProcessing(self, src_image):\n",
        "        self.img_gray = cv2.cvtColor(src_image, cv2.COLOR_BGR2GRAY)\n",
        "        _, self.img_binary = cv2.threshold(self.img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "        self.kernel = np.zeros((5,5), np.uint8)\n",
        "        self.img_binary = cv2.morphologyEx(self.img_binary, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "        return self.img_binary\n",
        "    \n",
        "    def Detect(self, binary_img):\n",
        "        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            x_cont, y_cont, width, height = cv2.boundingRect(contour)\n",
        "\n",
        "            length = max(width, height) + 30\n",
        "            img_num = np.zeros((length, length, 1), np.uint8)\n",
        "\n",
        "    #정사각형으로 window를 만들어주자\n",
        "            x_win, y_win = x_cont-(length-width)//2, y_cont-(length-height)//2\n",
        "\n",
        "    #test공간에 binary image input    \n",
        "            img_num = img_binary[y_win:y_win+length,x_win:x_win+length]\n",
        "\n",
        "            cv2_imshow(img_num)\n",
        "\n",
        "            img_num = cv2.resize(img_num, (28, 28), interpolation=cv2.INTER_AREA)/255\n",
        "            img_input = img_num.reshape(1, 28, 28, 1)\n",
        " \n",
        "            predict = model.predict(img_input)\n",
        "            answer = np.argmax(predict)\n",
        "            print(\"thils number is \" +str(answer),\"\\n\")\n",
        "\n",
        "    #color image에 sketch window\n",
        "            cv2.rectangle(img_color, (x_cont-10, y_cont-10), (x_cont+width+20, y_cont+height+20), (255, 0, 0), 3)\n",
        "\n",
        "    #window 위에 predict 표시\n",
        "    #cv2.putText(src, org, FontFace, Fontscale, color, thickness,... )\n",
        "            cv2.putText(img_color, str(answer), (x_cont+int(width*0.5), y_cont-10), cv2.FONT_HERSHEY_COMPLEX, 3, (0, 0, 255), 3)\n",
        "\n",
        "        return img_color\n",
        "\n",
        "\n",
        "mnist = Trace()\n",
        "\n",
        "img_color = Trace.GetImage(mnist,image='numbers2.jpg')\n",
        "cv2_imshow(img_color)\n",
        "img_binary = Trace.ImageProcessing(mnist,img_color)\n",
        "Trace.Detect(mnist,img_binary)\n",
        "cv2_imshow(img_color)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}