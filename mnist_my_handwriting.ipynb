{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "mount_file_id": "1FoXtcGqtNhjJXZYkj5FRrq_u4PRTtc8B",
      "authorship_tag": "ABX9TyOOhVljGwYrhMELsBkJjAlT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bangse94/hongik_ee/blob/master/mnist_my_handwriting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48QL9GfUyVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ===========================\n",
        "# import library\n",
        "# ===========================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "print(\"TensorFlow version : \", tf.__version__)\n",
        "#===========================\n",
        "# import mnist dataset\n",
        "#===========================\n",
        "(train_image, train_labels), (test_image, test_labels) = mnist.load_data()\n",
        "#===========================\n",
        "# reshape input data\n",
        "#===========================\n",
        "train_image = train_image.reshape(train_image.shape[0], 28, 28, 1)\n",
        "test_image = test_image.reshape(test_image.shape[0], 28, 28, 1)\n",
        "train_image = train_image.astype('float32')/255\n",
        "test_image = test_image.astype('float32')/255\n",
        "#===========================\n",
        "# train labels\n",
        "#===========================\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "#===========================\n",
        "# model creation by sequential class\n",
        "#===========================\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "#===========================\n",
        "# data augmentation\n",
        "#===========================\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        fill_mode='nearest')\n",
        "#===========================\n",
        "# model compile and training\n",
        "#===========================\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(train_image, train_labels, batch_size=128),\n",
        "                    steps_per_epoch=train_image.shape[0] // 128,\n",
        "                    validation_data=(test_image, test_labels),\n",
        "                    epochs=12)\n",
        "#===========================\n",
        "# model evaluate\n",
        "#===========================\n",
        "acc = model.evaluate(test_image, test_labels)\n",
        "print('evaluate accuracy:', acc[1])\n",
        "\n",
        "#===========================\n",
        "# save model\n",
        "#===========================\n",
        "model.save('mnist_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOVyFCpS8E6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "#===========================\n",
        "# image processing\n",
        "#===========================\n",
        "#load image\n",
        "img_color = cv2.imread(\"/content/numbers2.jpg\", cv2.IMREAD_COLOR)\n",
        "cv2_imshow(img_color)\n",
        "cv2.waitKey(0)\n",
        "#convert image color to gray\n",
        "img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "#make binary image from gray\n",
        "_,img_binary = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
        "#opening(morphology)\n",
        "kernel = np.ones((5,5), np.uint8)\n",
        "img_binary = cv2.morphologyEx(img_binary, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "cv2_imshow(img_binary)\n",
        "#===========================\n",
        "# detect\n",
        "#===========================\n",
        "#detect number contour\n",
        "contours, _ = cv2.findContours(img_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#===========================\n",
        "# predict\n",
        "#===========================\n",
        "for contour in contours:\n",
        "    x1, y1, width, height = cv2.boundingRect(contour)\n",
        "\n",
        "    #test하기 위한 공간 확보\n",
        "    length = max(width, height) + 80\n",
        "    img_num = np.zeros((length, length, 1), np.uint8)\n",
        "\n",
        "    #정사각형으로 window를 만들어주자\n",
        "    x2, y2 = x1-(length-width)//2, y1-(length-height)//2\n",
        "\n",
        "    #test공간에 binary image input    \n",
        "    img_num = img_binary[y2:y2+length,x2:x2+length]\n",
        "\n",
        "    cv2_imshow(img_num)\n",
        "\n",
        "    #load model and test\n",
        "    model = load_model('mnist_model.h5')\n",
        "\n",
        "    img_num = cv2.resize(img_num, (28, 28), interpolation=cv2.INTER_AREA)\n",
        "    img_num = img_num/255.0\n",
        "    img_input = img_num.reshape(1, 28, 28, 1)\n",
        "    predictions = model.predict(img_input)\n",
        "\n",
        "    answer = np.argmax(predictions)\n",
        "    print(\"thils number is \" +str(answer),\"\\n\")\n",
        "\n",
        "    #color image에 sketch window\n",
        "    cv2.rectangle(img_color, (x1, y1), (x1+width, y1+height), (255, 0, 0), 3)\n",
        "\n",
        "    #window 위에 predict 표시\n",
        "    #cv2.putText(src, org, FontFace, Fontscale, color, thickness, )\n",
        "    cv2.putText(img_color, str(answer), (x1+int(width*0.5), y1-10), cv2.FONT_HERSHEY_COMPLEX, 3, (0, 0, 255), 3)\n",
        "\n",
        "#===========================\n",
        "# show result on image\n",
        "#===========================\n",
        "cv2_imshow(img_color)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
